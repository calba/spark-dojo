{
 "metadata": {
  "name": "Stratified sampling"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "# Stratified sampling\nIn this script we are going to sample a dataset of words, but we'll sample carefully to avoid removing subsets with low occurrence\nIn other words, we'll perform a _stratified sampling_\n\nIn our case we'll use the word length as the feature whose statistics we want to preserve, so we will perform an 1% sampling *for each word length*. And we'll change the sampling ratio for the long words (which are typically rare), so as to preserve them.\n\n## 1. Stats extraction"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# We start reading the file from HDFS into a RDD                                                        \nwords = sc.textFile( \"hdfs:///user/{0}/data/quijote-words.txt\".format(sc.sparkUser()) )\ntotal_words = words.count()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Now we compute the subclasses. This is done creating a (k,v) RDD, by mapping using word length as the key                                                 \nwordsByLength = words.map( lambda x : (len(x),x) )",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Let's take a peek to see what we've got\nwordsByLength.take( 10 )",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 3,
       "text": "[(2, u'El'),\n (9, u'ingenioso'),\n (7, u'hidalgo'),\n (3, u'don'),\n (7, u'Quijote'),\n (2, u'de'),\n (2, u'la'),\n (6, u'Mancha'),\n (4, u'TASA'),\n (2, u'Yo')]"
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Ok, check class cardinality\n# Compute the fraction of words having each length                                          \nlengthStats = words.map( lambda x : (len(x),1) ).reduceByKey( add ).sortByKey( False )",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Get those figures back to the driver program, since we need to work with them\nstats = lengthStats.collect()\nstats",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 5,
       "text": "[(21, 1),\n (19, 2),\n (18, 2),\n (17, 8),\n (16, 41),\n (15, 112),\n (14, 339),\n (13, 844),\n (12, 1737),\n (11, 3247),\n (10, 7381),\n (9, 13106),\n (8, 20110),\n (7, 29962),\n (6, 36780),\n (5, 45829),\n (4, 36715),\n (3, 66388),\n (2, 89307),\n (1, 29303),\n (0, 2)]"
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "As we suspected, long words are exceedingly rare, while short words are fairly common (there is a bogus class of length 0, probably containing a couple of empty strings that slipped our processing).\n\nOut of curiosity, let's find the champions in word length"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "wordsByLength.filter( lambda x : x[0]>16 ).sortByKey(False).collect()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": "[(21, u'bienintencionadamente'),\n (19, u'estraordinariamente'),\n (19, u'extraordinariamente'),\n (18, u'desembarazadamente'),\n (18, u'correspondi\\xe9ndoles'),\n (17, u'estrech\\xedsimamente'),\n (17, u'convirti\\xe9ndoseles'),\n (17, u'asombradoPregunt\\xf3'),\n (17, u'desalumbradamente'),\n (17, u'desagradecimiento'),\n (17, u'desagradecimiento'),\n (17, u'Desagradecimiento'),\n (17, u'desagradecimiento')]"
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "## 2. Local processing\n\nOk, now let's manipulate the frequency stats to come up with the sampling fractions we want.\n\nFor training purposes, we'll use NumPy for this (though it's not actually necessary). So let's import it."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import numpy as np",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Now we convert our collected stats into a NumPy array\nstatsM = np.array( stats )",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# How many words in total?\ntotal = sum(statsM[::,1])\ntotal",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": "381216"
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# And what are the probabilities?\nfrom __future__ import division  # ensure we're using floating point division\nfraction = statsM[::,1]/total",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Stack the fractions into our array\nstatsM2 = np.c_[statsM,fraction]",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# See what we've got. To avoid that ugly scientific notation, we change NumPy presentation options\nnp.set_printoptions(suppress=True)\nstatsM2",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": "array([[    21.        ,      1.        ,      0.00000262],\n       [    19.        ,      2.        ,      0.00000525],\n       [    18.        ,      2.        ,      0.00000525],\n       [    17.        ,      8.        ,      0.00002099],\n       [    16.        ,     41.        ,      0.00010755],\n       [    15.        ,    112.        ,      0.0002938 ],\n       [    14.        ,    339.        ,      0.00088926],\n       [    13.        ,    844.        ,      0.00221397],\n       [    12.        ,   1737.        ,      0.00455647],\n       [    11.        ,   3247.        ,      0.00851748],\n       [    10.        ,   7381.        ,      0.01936173],\n       [     9.        ,  13106.        ,      0.03437946],\n       [     8.        ,  20110.        ,      0.05275225],\n       [     7.        ,  29962.        ,      0.07859586],\n       [     6.        ,  36780.        ,      0.09648074],\n       [     5.        ,  45829.        ,      0.12021793],\n       [     4.        ,  36715.        ,      0.09631023],\n       [     3.        ,  66388.        ,      0.17414799],\n       [     2.        ,  89307.        ,      0.23426876],\n       [     1.        ,  29303.        ,      0.07686718],\n       [     0.        ,      2.        ,      0.00000525]])"
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Ok, as a general rule we want 1% of data for each category\nsample_fractions = np.ones( fraction.shape )*0.01",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# but: underrepresented categories (less than 100 instances) we want at 100%\n# and very rare categories (less than 20 instances) we want in full\nsample_fractions[ statsM2[:,1] < 100 ] = 0.1\nsample_fractions[ statsM2[:,1] < 20 ] = 1",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Check those fractions\nsample_fractions",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 16,
       "text": "array([ 1.  ,  1.  ,  1.  ,  1.  ,  0.1 ,  0.01,  0.01,  0.01,  0.01,\n        0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n        0.01,  0.01,  1.  ])"
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Construct the dict \"key:fraction\" for the stratified sampling\ns = dict( zip(map(int,statsM[:,0]),sample_fractions) )\ns",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 17,
       "text": "{0: 1.0,\n 1: 0.01,\n 2: 0.01,\n 3: 0.01,\n 4: 0.01,\n 5: 0.01,\n 6: 0.01,\n 7: 0.01,\n 8: 0.01,\n 9: 0.01,\n 10: 0.01,\n 11: 0.01,\n 12: 0.01,\n 13: 0.01,\n 14: 0.01,\n 15: 0.01,\n 16: 0.10000000000000001,\n 17: 1.0,\n 18: 1.0,\n 19: 1.0,\n 21: 1.0}"
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "## 3.Sampling\nNow we've got the items grouped by categories, and the fractions we want to sample for each category, let's do it"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Sample!\nwordsSampledbyLength = wordsByLength.sampleByKey(False,s)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# See how many we've got overall\nsampled = wordsSampledbyLength.count()\nfraction = sampled/total_words\nfraction",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 19,
       "text": "0.009729392260555695"
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Check amount per category\nlengthStatsSampled = wordsSampledbyLength.mapValues( lambda x : 1 ).reduceByKey( add ).sortByKey( False )\nlengthStatsSampled.collect()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 20,
       "text": "[(21, 1),\n (19, 2),\n (18, 2),\n (17, 8),\n (16, 3),\n (15, 1),\n (14, 2),\n (13, 8),\n (12, 19),\n (11, 31),\n (10, 72),\n (9, 97),\n (8, 179),\n (7, 293),\n (6, 346),\n (5, 487),\n (4, 368),\n (3, 668),\n (2, 848),\n (1, 272),\n (0, 2)]"
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# An example of what we have\nwordsSampledbyLength.take(10)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": "[(2, u'de'),\n (2, u'un'),\n (5, u'libro'),\n (1, u'y'),\n (6, u'dellos'),\n (11, u'acogimiento'),\n (2, u'de'),\n (3, u'tan'),\n (8, u'engendra'),\n (6, u'alguna')]"
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}